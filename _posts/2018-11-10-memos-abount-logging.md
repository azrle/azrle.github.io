---
layout: post
tags: [logging, tech]
---

# 为什么要Logging

日志的种类多种多样，系统日志、访问日志、审计日志、事件日志、事务日志、消息日志等等，我想通过日志的目的，来把日志分为四类。我们为什么要Logging？

1. 还原现场，Debugging。在系统出现问题或是为了检查系统是否出问题时，我们常常会去查看日志，此种日志多是human-readable 的。可以是格式化的日志，也常见非格式化的日志。
2. 用于监视、统计、取证等的分析。用于这种用途的日志很多，例如访问日志、审计日志等。为了方便系统处理分析，多是格式化的数据。
3. 数据传递。日志也经常用作系统间的信息传递，一个系统的日志可以是另一个系统的输入。譬如，MySQL 的主从间的数据传递就是借助Binlog 的。由于多是系统间的内部信息传递，二进制格式(协议)比较多。btw，由于事务日志，很多数据库本身就是一个日志系统 (*"THE LOG IS THE DATABASE"*)。
4. 数据备份及恢复。日志也有用于数据的备份的。数据库系统就常有Write-ahead Logging 等事务日志(如Innodb Log)来恢复状态和数据。MySQL 也有做Binlog 备份及恢复的。

一条日志记录，可能出现在多个日志中，一个日志也可能被用于多个目的。同样，也常见日志由于需求在不断转化、整合、归档。

# 怎么Logging

## 日志里应该写些什么？

日志的用途是决定如何Logging 的一个重要因素。

对于用于还原现场的日志，Logging 应该像打欠条一样，什么时间谁向谁接了多少钱，应该是写清楚的。日志不应该仅仅包含事件的简单叙述。譬如说，一个多进程(线程)或是分布式的系统中，看日志的时候我们有时想要固定在某个进程或是服务器的日志记录上看，假设我们手上只有日志文件，且日志文件中没有区分进程或是服务器，这就使得我们区分单独进程或是服务器的难度增大。再譬如说，一个系统对于多个资源对象进行操作，如果最终失败了，我们常常会想知道是全失败了，还是部分失败了，失败的资源对象是什么。再举一例，连接数据库失败的时候，我们想知道连接的数据库的地址，是Hostname 的话，DNS 的解析结果又是多少；失败的原因是什么，是Connection Timeout 还是Connection Refused。在做Logging 的时候应该充分考虑失败情况下Debug 的场景，如果觉得Debug 的时候需要这个信息，就应该放进日志中。当然，需要Debug 时候需要什么样的信息，很多时候取决于经验，譬如经历过AWS Zone 之间的网络问题后，可能就会把链接双方的Zone 信息写入日志。

有时候觉得，程序员既是犯人又是侦探。为了自己和别人能更快破案，当犯人的时候(写程序的时候)，应当多考虑考虑案发时候该留下的线索和证据。

对于其他用途的日志，写入的内容多是由需求决定的。访问日志中可能有访问目标的信息，协议Header 的信息等，如果是Proxy 可能还有上下游的信息。用于监控和性能分析的日志往往有响应时间、调用模块、Status code 等信息。这里需要注意的是，如果一个请求没有被正常完成，是否能够正确地输出到日志。

关于日志内容，还有两点想要讨论的。

一点是关于时间。时间，一直是计算机科学中一个重要问题。日志中往往会有时间戳(Timestamp)，时间戳应该是可以定位到一个绝对时间的，格式的问题稍后再讨论，首先我个人觉得日志中的时间应该竟可能做到统一，比如用同一个时区的时间等。这样可以减少系统的处理错误，也能减少人类读日志时造成的误会。另外，时间不总是一个令人相信的东西，不同服务器的时钟可能是不同步的(目前也不可能完全同步)，时间也可能会跳跃、会回滚、会有闰秒等等。在处理日志的时间的时候应该小心。

还有一点是关于安全和隐私的。当写入日志的时候，应该意识到谁能访问到这个日志，是否有安全隐患，是否符合隐私协议。譬如说，是否把密码等敏感信息写入日志，甚至是明文的 ([Twitter](https://blog.twitter.com/official/en_us/topics/company/2018/keeping-your-account-secure.html)，[Github](GitHub Accidentally Recorded Some Plaintext Passwords in Its Internal Logs))。特别的，有些条款，譬如GDPR (European Union’s General Data Protection Regulation)，对于日志是有要求的，随意的写入个人信息会招致法律问题，甚至在写入用户IP 地址的时候都得小心翼翼。另外该协议还规定了一个“遗忘权”，用户有权要求你删除用户自己的个人信息，包括日志里的。这些都是在写入日志的时候需要考虑的。

## 日志的格式

日志的格式各种各样，如果不使用日志协议(binary log, [syslog](https://tools.ietf.org/html/rfc5424) 等)，比起非结构化的日志，结构化的日志更有利于机读，应该被建议尽量使用。日志的结构体虽然有很多选择，比如json (streaming), csv, tsv, ltsv 等。就接触的一些日志服务来说，json 应该来说是比较常见的。写日志的时候尽可能采用一些库，比如go 语言中有zap，这样比较容易统一格式。对于一些现有的通用格式，尽量遵从标准，比如，对于时间 [rfc3339](https://www.ietf.org/rfc/rfc3339.txt)，国家代码 [ISO 3166-1](https://en.wikipedia.org/wiki/ISO_3166-1)，IPv6 地址 [rfc5952](https://tools.ietf.org/html/rfc5952) 等等。另外，写日志的时候还应该小心一些特殊情况。比如一些二进制数据，是否要先encode 一下，多行日志是否要先转成单行日志，日志是否过长，日志的接收方是否有些特殊要求等。

## 往哪里写？

日志往哪里写一直都有争论，根据不同场景也可能不同。有的往标准输出写，有的往文件里写，有的往远程服务器写。

对于往标准输出写的，多见于一些“容器”内的程序，写出来的log 会被重定向或是捕获、分拣，如果有需要再由一些组件(如fluentd)收集发送至远端服务器。这种方法，符合[The Twelve-Factor App](https://12factor.net/logs)。应用不需要管理文件、缓冲区，直接把日志flush 到stdout 就好，这样使得应用能够更关注自己逻辑。然而，这种方法依赖于执行环境，假设一个应用产生两种需要归档的日志，执行环境就需要做到高效的、没有错误的捕获、分拣、管理日志。这其实是将应用的难题推给了下层的执行环境。为了做好这点，就必须和应用商量好协议(为了分拣)、控制好日志流量(为了管理日志)等。商量的最后，有人会问，为什么我们不直接用现成的库把日志写入文件呢？

对于写文件，由于历史悠久，基本上各种编程语言都有比较成熟的库了。有的库甚至能够帮你logrotate。这里就不讨论写文件的具体细节了。说到logrotate，这里就有个有意思的问题了，以何种标准logrotate？如果按照文件来大小来logrotate，那么如果按时间做归档的时候我们可能就需要对于文件进行再次读取、处理，才能进行归档。另一方面，如果我们按时间来归档，又需要注意时间的分度，譬如如果按天来划分的话，可能磁盘存不下一天的日志。

最后是关于往远程服务器写的情况。由于磁盘的限制、服务器生命周期等因素，一个日志一般不会长期停留在一个服务器的本地磁盘上，在磁盘、服务器退役的时候也往往会把日志转移到远程服务器上。这就带来了一个新的想法，为什么不直接把日志通过网络输出到远程服务器上？这个想法其实很好，如果正确实现，也会是一个十分理想的解决方案。问题在于，这种方案事实上在引入远程服务器的同时，增加了系统的复杂性，意味着带来了更多出错的情况。其中就包括有，1) 采用阻塞的方法(等待应用层ack)输出log 到远程服务器上，远程服务的抖动、网络的抖动直接影响应用的响应时间；2) log 传输协议及实现有问题，一个损坏的日志记录导致后续的日志记录都不正常；3) 远程日志服务器容易瓶颈；4) 本地文件进行缓冲，外部日志服务器的长时间downtime 导致缓冲区超出大小，必须选择丢弃(因为远程服务器容量大，logging 的时候没有考虑本地缓冲区长时间堆积的后果)；5) 远程日志服务器出错，日志丢失，无法恢复；6) 网路原因日志无法发出，需要进服务器查看缓冲区，并做特殊处理；7) 需要增加监视，来检查缓冲区是否堆积。

实际的场景可能是多种方式的混合，就目前来说，在本地先写日志(无论是直接写文件还是stdout 重定向)，再通过别的组件送往远程服务器是一个比较常见的解决方案。本地文件不仅可以充当缓冲区，同时也方便规模较小的debug。



# 日志的管理与生命周期

日志的管理的难点主要来于两个方面，一方面确保日志尽量不要丢失，另一方面是控制日志的存取以及生命周期。

如果所有的日志都发往远程日志服务器，日志还会丢失吗？答案是，仍然有可能丢失。譬如磁盘损害导致的本地日志或缓冲区的丢失。另外，我们能实时地发送日志到远程服务器吗？我们真的需要把所有日志实时发送给远程服务器处理吗？如果是为了监视，我们可能不需要完整的日志，只需要统计后的信息。如果我们需要Debug，我们也可能只需要一些样本。我并**不认为**，**完整日志的实时性**是一个常见的迫切需求。

我们能做的就是尽量考虑到一些边界情况，采取一些较为可靠、保险的方法进行日志回收，而不单单是将日志发往远程日志服务器。举一个运维的例子，在AWS 云环境上，当一个Instance 由于AWS 自身的原因突然网络不通了，最后甚至无法再使用了，如果常规的日志回收需要Instance 启动进行操作的话，在这种情况下就比较难了。于是可以将日志回收从目标服务器(Instance) 上回收改为将服务器的Volume 挂载到一台回收服务器上进行回收，这样就能避免这种问题。当然，这同时会带来别的问题，这里就不做进一步讨论。

日志有一个很大的特性，就是他是不能被修改的。Tripwire 等软件也会被用来保证这一点。结合之前提及的安全和隐私问题，这就使得日志存取需要设置有相应的权限。同时为了方便分析，读取应该是相对快速的。现今许多云提供商提供了日志保存服务以及Object storage 服务，后者适用于长期廉价地保存日志，也能控制保存周期，甚至有时候还直接能用于分析(如AWS Athena)。于是常常成为了日志的最终归宿。而用于分析的日志部分，也很可能会辗转于多个数据库或是分析系统，存在于各式各样的存储系统中，但同时这部分的日志带来了另一个问题，需要删除的时候我们是否能够删除干净。事实上，正确的删除数据在很多时候要比存储它难上很多，因为很多数据(日志)在存储的时候根本没想过，在什么情况下会因为什么而需要被(连带)删除。说到删除数据，这里还有一个问题就是日志的保存时间，而这个时间往往是业务上或是法律上的要求，每个地区也可能不一样。有的地区为了隐私考虑可能要求你不能保存太久，有的地区为了监察考虑可能要求你不能保存太短。当然还有保存位置等等各种非技术上带来的严苛要求。



综上，结合日志的不同需求，在日志的内容、格式、保存方法、管理方法、生命周期上都会有所不同。读写日志看似简单，在细节上还是有很多值得根据需求进行探讨的地方。
